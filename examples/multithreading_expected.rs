// Auto-generated Rust code from C++ source
// Generated by Hybrid Transpiler
//
// Multithreading Examples - Expected Rust Output

use std::sync::{Arc, Mutex, RwLock, Condvar, atomic::{AtomicI32, AtomicBool, Ordering}};
use std::thread;
use std::collections::VecDeque;

/**
 * Example 1: Basic thread creation and joining
 */
pub struct SimpleThreadExample {
    data: i32,
}

impl SimpleThreadExample {
    pub fn new() -> Self {
        Self { data: 0 }
    }

    pub fn worker_function(&mut self, value: i32) {
        self.data += value;
    }

    pub fn run_threads(&mut self) {
        // Note: Rust requires Arc<Mutex<T>> for shared mutable state across threads
        let data = Arc::new(Mutex::new(0i32));

        let data1 = Arc::clone(&data);
        let t1 = thread::spawn(move || {
            let mut d = data1.lock().unwrap();
            *d += 10;
        });

        let data2 = Arc::clone(&data);
        let t2 = thread::spawn(move || {
            let mut d = data2.lock().unwrap();
            *d += 20;
        });

        // Wait for threads to complete
        t1.join().unwrap();
        t2.join().unwrap();
    }
}

/**
 * Example 2: Thread-safe counter with mutex
 */
pub struct ThreadSafeCounter {
    count: i32,
    mutex: Mutex<i32>,
}

impl ThreadSafeCounter {
    pub fn new() -> Self {
        Self {
            count: 0,
            mutex: Mutex::new(0),
        }
    }

    pub fn increment(&self) {
        let mut count = self.mutex.lock().unwrap();
        *count += 1;
    }

    pub fn decrement(&self) {
        let mut count = self.mutex.lock().unwrap();
        *count -= 1;
    }

    pub fn get_value(&self) -> i32 {
        let count = self.mutex.lock().unwrap();
        *count
    }
}

/**
 * Example 3: Atomic operations
 */
pub struct AtomicCounter {
    count: AtomicI32,
}

impl AtomicCounter {
    pub fn new() -> Self {
        Self {
            count: AtomicI32::new(0),
        }
    }

    pub fn increment(&self) {
        self.count.fetch_add(1, Ordering::SeqCst);
    }

    pub fn decrement(&self) {
        self.count.fetch_sub(1, Ordering::SeqCst);
    }

    pub fn get_value(&self) -> i32 {
        self.count.load(Ordering::SeqCst)
    }
}

/**
 * Example 4: Producer-Consumer with condition variable
 */
pub struct ProducerConsumer {
    buffer: Mutex<Vec<i32>>,
    cv: Condvar,
    max_buffer_size: usize,
    done: AtomicBool,
}

impl ProducerConsumer {
    pub fn new() -> Self {
        Self {
            buffer: Mutex::new(Vec::new()),
            cv: Condvar::new(),
            max_buffer_size: 10,
            done: AtomicBool::new(false),
        }
    }

    pub fn produce(&self, value: i32) {
        let mut buffer = self.buffer.lock().unwrap();

        // Wait until buffer has space
        buffer = self.cv.wait_while(buffer, |b| b.len() >= self.max_buffer_size).unwrap();

        buffer.push(value);
        self.cv.notify_one();
    }

    pub fn consume(&self) -> i32 {
        let mut buffer = self.buffer.lock().unwrap();

        // Wait until buffer has data
        buffer = self.cv.wait_while(buffer, |b| {
            b.is_empty() && !self.done.load(Ordering::SeqCst)
        }).unwrap();

        if buffer.is_empty() {
            return -1; // No more data
        }

        let value = buffer.pop().unwrap();
        self.cv.notify_one();

        value
    }

    pub fn finish(&self) {
        self.done.store(true, Ordering::SeqCst);
        self.cv.notify_all();
    }
}

/**
 * Example 5: Shared data with reader-writer lock
 */
pub struct SharedData {
    data: i32,
    mutex: RwLock<i32>,
}

impl SharedData {
    pub fn new() -> Self {
        Self {
            data: 0,
            mutex: RwLock::new(0),
        }
    }

    // Multiple readers can read simultaneously
    pub fn read(&self) -> i32 {
        let data = self.mutex.read().unwrap();
        *data
    }

    // Only one writer at a time
    pub fn write(&mut self, value: i32) {
        let mut data = self.mutex.write().unwrap();
        *data = value;
    }
}

/**
 * Example 6: Detached thread
 */
pub struct DetachedThreadExample {}

impl DetachedThreadExample {
    pub fn new() -> Self {
        Self {}
    }

    pub fn background_task(&self) {
        // Do some work
    }

    pub fn launch_background_task(&self) {
        let handle = thread::spawn(|| {
            // Background task
        });

        // Note: Rust threads are always joinable
        // To achieve detached behavior, use std::mem::forget
        std::mem::forget(handle);
    }
}

/**
 * Example 7: Multiple threads with closure
 */
pub fn parallel_computation() {
    let result = Arc::new(AtomicI32::new(0));
    const NUM_THREADS: i32 = 4;

    let mut handles = vec![];

    for i in 0..NUM_THREADS {
        let result_clone = Arc::clone(&result);
        let handle = thread::spawn(move || {
            // Each thread adds its index to result
            result_clone.fetch_add(i, Ordering::SeqCst);
        });
        handles.push(handle);
    }

    // Wait for all threads
    for handle in handles {
        handle.join().unwrap();
    }
}

/**
 * Example 8: Thread pool pattern
 */
pub struct ThreadPool {
    workers: Vec<thread::JoinHandle<()>>,
    stop: Arc<AtomicBool>,
    cv: Arc<Condvar>,
    queue_mutex: Arc<Mutex<bool>>,
}

impl ThreadPool {
    pub fn new(num_threads: usize) -> Self {
        let stop = Arc::new(AtomicBool::new(false));
        let cv = Arc::new(Condvar::new());
        let queue_mutex = Arc::new(Mutex::new(false));
        let mut workers = Vec::new();

        for _ in 0..num_threads {
            let stop_clone = Arc::clone(&stop);
            let cv_clone = Arc::clone(&cv);
            let mutex_clone = Arc::clone(&queue_mutex);

            let handle = thread::spawn(move || {
                loop {
                    let lock = mutex_clone.lock().unwrap();

                    let _lock = cv_clone.wait_while(lock, |_| {
                        !stop_clone.load(Ordering::SeqCst)
                    }).unwrap();

                    if stop_clone.load(Ordering::SeqCst) {
                        return;
                    }

                    // Process task
                }
            });

            workers.push(handle);
        }

        Self {
            workers,
            stop,
            cv,
            queue_mutex,
        }
    }
}

impl Drop for ThreadPool {
    fn drop(&mut self) {
        self.stop.store(true, Ordering::SeqCst);
        self.cv.notify_all();

        for worker in self.workers.drain(..) {
            worker.join().unwrap();
        }
    }
}
